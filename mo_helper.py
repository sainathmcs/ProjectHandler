#!/usr/bin/env python3
"""
mo_helper.py

This CLI tool initializes and maintains a model task project with a defined folder
structure and a YAML mapping (Mo.yaml). It supports operations such as init, add,
delete, move, validate, and wrapper update.

The wrapper update functionality parses the task source code to detect sys.argv
assignments and then generates a wrapper that explicitly assigns each expected
command-line parameter to a variable (e.g. a = sys.argv[1]) in the same order.
"""

import os
import re
import shutil
import subprocess
import tempfile
import click
import yaml
import ast

# =============================================================================
# Default Template Constants
# =============================================================================

DEFAULT_REQ_TEMPLATE = "pyinstaller\ncoverage\npytest\n"

DEFAULT_WRAPPER_TEMPLATE = '''#!/usr/bin/env python3
"""
Wrapper for task: {task_name}
This wrapper calls the executable generated by pyinstaller in the dist folder.
It expects no CLI parameters.
"""
import os
import sys
import subprocess

def wrapper():
    executable = os.path.join(os.path.dirname(__file__), "..", "dist", "{task_name}")
    result = subprocess.run([executable] + sys.argv[1:])
    sys.exit(result.returncode)

if __name__ == '__main__':
    wrapper()
'''

DEFAULT_TASK_TEMPLATE = '''"""
Skeleton for task: {task_name}
"""

def main():
    print("Running task {task_name}...")

if __name__ == '__main__':
    main()
'''

DEFAULT_BUILD_SH_TEMPLATE = """#!/usr/bin/env bash

# Parse optional arguments: --skip_build and --skip_coverage
SKIP_BUILD=0
SKIP_COVERAGE=0
while [[ "$#" -gt 0 ]]; do
    case $1 in
        --skip_build) SKIP_BUILD=1 ;;
        --skip_coverage) SKIP_COVERAGE=1 ;;
        *) echo "Unknown parameter passed: $1"; exit 1 ;;
    esac
    shift
done

# Create temporary directory for virtual environment
VENV_TMP_DIR=$(mktemp -d)
echo "Creating virtual environment in temporary directory: $VENV_TMP_DIR"
python3 -m venv "$VENV_TMP_DIR/venv"
source "$VENV_TMP_DIR/venv/bin/activate"

# Create temporary directory for uv installation and install uv
UV_TMP_DIR=$(mktemp -d)
echo "Installing uv in temporary directory: $UV_TMP_DIR"
pip install --target="$UV_TMP_DIR" uv
export PYTHONPATH="$UV_TMP_DIR:$PYTHONPATH"

echo "Installing requirements..."
uv pip install -r requirements.txt

if [ "$SKIP_BUILD" -eq 0 ]; then
    echo "Building tasks with pyinstaller..."
    # BEGIN PYINSTALLER
    # (pyinstaller commands will be inserted here)
    # END PYINSTALLER
else
    echo "Skipping build as per --skip_build flag."
fi

if [ "$SKIP_COVERAGE" -eq 0 ]; then
    echo "Running tests with coverage..."
    coverage run --source=. -m pytest tests/
    coverage report
    coverage xml -o coverage.xml
else
    echo "Skipping coverage as per --skip_coverage flag."
fi

# Cleanup
deactivate
rm -rf "$VENV_TMP_DIR"
rm -rf "$UV_TMP_DIR"
"""

DEFAULT_TEST_TEMPLATE = '''import pytest

def test_{task_name}():
    """
    TODO: Implement tests for task: {task_name}
    """
    assert True
'''

# =============================================================================
# Template Getter Functions
# =============================================================================

def get_requirements_template():
    return DEFAULT_REQ_TEMPLATE

def get_wrapper_template(task_name):
    return DEFAULT_WRAPPER_TEMPLATE.format(task_name=task_name)

def get_task_template(task_name):
    return DEFAULT_TASK_TEMPLATE.format(task_name=task_name)

def get_build_sh_template():
    return DEFAULT_BUILD_SH_TEMPLATE

# =============================================================================
# Backup, Rename, and Safe Write Helpers
# =============================================================================

def backup_path(path):
    # Back up a file or folder to a temporary directory.
    backup_dir = tempfile.mkdtemp(prefix="mo_helper_backup_")
    base_name = os.path.basename(path)
    dest = os.path.join(backup_dir, base_name)
    if os.path.isfile(path):
        shutil.copy2(path, dest)
    elif os.path.isdir(path):
        shutil.copytree(path, dest)
    return backup_dir

def safe_write_file(file_path, content):
    # Write content safely to file_path, backing up any existing file.
    if os.path.exists(file_path):
        overwrite = click.confirm(f"File '{file_path}' exists. Overwrite?", default=False)
        if not overwrite:
            click.echo(f"Skipped writing to '{file_path}'.")
            return
        else:
            backup = backup_path(file_path)
            click.echo(f"Backed up '{file_path}' to '{backup}'.")
    with open(file_path, "w") as f:
        f.write(content)
    click.echo(f"Wrote file '{file_path}'.")

def safe_create_directory(dir_path):
    # Create a directory; if it exists, ask whether to overwrite it.
    if os.path.exists(dir_path):
        overwrite = click.confirm(f"Directory '{dir_path}' exists. Overwrite?", default=False)
        if not overwrite:
            click.echo(f"Using existing directory '{dir_path}'.")
            return
        else:
            backup = backup_path(dir_path)
            click.echo(f"Backed up directory '{dir_path}' to '{backup}'.")
            shutil.rmtree(dir_path)
    os.makedirs(dir_path, exist_ok=True)
    click.echo(f"Created directory '{dir_path}'.")

def rename_path(src, dst, base_dir="."):
    # Normalize the paths using os.path.normpath for Windows compatibility.
    src_norm = os.path.normpath(src)
    dst_norm = os.path.normpath(dst)
    try:
        # Try to use git mv first.
        subprocess.run(["git", "mv", src_norm, dst_norm], cwd=base_dir, check=True)
        click.echo(f"Renamed '{src_norm}' to '{dst_norm}' using git mv.")
    except Exception as e:
        click.echo(f"git mv failed: {e}. Falling back to os.rename.")
        try:
            os.rename(src_norm, dst_norm)
            click.echo(f"Renamed '{src_norm}' to '{dst_norm}' using os.rename.")
        except Exception as e2:
            click.echo(f"Error renaming '{src_norm}' to '{dst_norm}' using os.rename: {e2}")

# =============================================================================
# Data Structures: Task and TaskGroup
# =============================================================================

class Task:
    def __init__(self, pos, task_name, folder, letter=None):
        self.pos = int(pos)
        self.letter = letter
        self.task_name = task_name
        self.folder = folder

    def full_position(self):
        return f"{self.pos}" if self.letter is None else f"{self.pos}{self.letter}"

    def __str__(self):
        return f"[{self.full_position()}] {self.task_name} ({self.folder})"

class TaskGroup:
    def __init__(self, pos):
        self.pos = int(pos)
        self.tasks = []
        self.prev = None
        self.next = None

    def is_parallel(self):
        return len(self.tasks) > 1 or (self.tasks and self.tasks[0].letter is not None)

    def __str__(self):
        if self.is_parallel():
            inner = ", ".join(str(t) for t in self.tasks)
            return f"Group {self.pos}: [Parallel: {inner}]"
        elif self.tasks:
            return f"Group {self.pos}: {self.tasks[0]}"
        else:
            return f"Group {self.pos}: <empty>"

# =============================================================================
# Folder Pattern and Task Group Builder
# =============================================================================

def get_folder_pattern():
    return re.compile(r"^(\d+)([a-z]*)_(.+)$")

def build_task_groups(base_dir="."):
    yaml_path = os.path.join(base_dir, "Mo.yaml")
    if not os.path.exists(yaml_path):
        raise FileNotFoundError("Mo.yaml not found in current directory!")
    with open(yaml_path, "r") as f:
        mo = yaml.safe_load(f)
    tasks_yaml = mo.get("tasks", {})
    groups = {}
    for key, value in tasks_yaml.items():
        tg = TaskGroup(key)
        if isinstance(value, dict):
            for letter, task_name in value.items():
                folder_name = f"{key}{letter}_{task_name}"
                tg.tasks.append(Task(key, task_name, folder_name, letter))
        else:
            folder_name = f"{key}_{value}"
            tg.tasks.append(Task(key, value, folder_name))
        groups[int(key)] = tg
    folder_pattern = get_folder_pattern()
    found_folders = {}
    for d in os.listdir(base_dir):
        full_path = os.path.join(base_dir, d)
        if os.path.isdir(full_path):
            m = folder_pattern.match(d)
            if m:
                num, letter, _ = m.groups()
                found_folders[f"{num}{letter}"] = d
    for group in groups.values():
        for task in group.tasks:
            if task.full_position() not in found_folders:
                raise ValueError(f"Folder for task {task.full_position()} ({task.task_name}) not found!")
            task.folder = found_folders[task.full_position()]
    sorted_positions = sorted(groups.keys())
    task_groups = [groups[pos] for pos in sorted_positions]
    for i, group in enumerate(task_groups):
        if i > 0:
            group.prev = task_groups[i - 1]
        if i < len(task_groups) - 1:
            group.next = task_groups[i + 1]
    return task_groups, mo

# =============================================================================
# YAML and Folder Shifting Helpers
# =============================================================================

def save_yaml(mo, base_dir="."):
    safe_write_file(os.path.join(base_dir, "Mo.yaml"), yaml.dump(mo))

def shift_task_groups(start_pos, mo, base_dir="."):
    tasks_yaml = mo.get("tasks", {})
    folder_pattern = get_folder_pattern()
    task_folders = {}
    for d in os.listdir(base_dir):
        full_path = os.path.join(base_dir, d)
        if os.path.isdir(full_path):
            m = folder_pattern.match(d)
            if m:
                num, letter, _ = m.groups()
                pos = int(num)
                if pos >= int(start_pos):
                    task_folders[d] = full_path
    sorted_folders = sorted(task_folders.keys(), reverse=True)
    for folder_name in sorted_folders:
        m = folder_pattern.match(folder_name)
        if m:
            num, letter, task_name = m.groups()
            pos = int(num)
            new_pos = str(pos + 1)
            old_path = task_folders[folder_name]
            new_folder = f"{new_pos}{letter}_{task_name}"
            if os.path.exists(old_path):
                backup = backup_path(old_path)
                click.echo(f"Backed up folder '{old_path}' to '{backup}'.")
                rename_path(old_path, new_folder, base_dir)
    keys_to_shift = sorted([int(k) for k in tasks_yaml.keys() if int(k) >= int(start_pos)], reverse=True)
    for k in keys_to_shift:
        new_key = str(k + 1)
        tasks_yaml[new_key] = tasks_yaml.pop(str(k))
    mo["tasks"] = tasks_yaml

def parse_position(pos_str):
    digits = ""
    letters = ""
    for ch in pos_str:
        if ch.isdigit():
            digits += ch
        else:
            letters += ch
    if not digits:
        raise ValueError("Position must start with a number.")
    return digits, letters if letters else None

# =============================================================================
# PyInstaller and Test Script Helpers
# =============================================================================

def generate_pyinstaller_commands(base_dir="."):
    try:
        task_groups, _ = build_task_groups(base_dir)
    except Exception as e:
        click.echo(f"Error generating pyinstaller commands: {e}")
        return ""
    commands = []
    for group in task_groups:
        for task in group.tasks:
            cmd = f'echo "Building executable for task {task.full_position()} - {task.task_name}"\n'
            cmd += f'pyinstaller --onefile --workpath=$(mktemp -d) --distpath=$(pwd)/dist "$(pwd)/{task.folder}/{task.task_name}.py"\n'
            commands.append(cmd)
    return "\n".join(commands)

def update_build_sh(base_dir="."):
    build_sh_path = os.path.join(base_dir, "build.sh")
    if not os.path.exists(build_sh_path):
        click.echo("build.sh not found, skipping update of pyinstaller commands.")
        return
    with open(build_sh_path, "r") as f:
        content = f.read()
    pattern = re.compile(r'(# BEGIN PYINSTALLER\n)(.*?)(# END PYINSTALLER)', re.DOTALL)
    new_commands = generate_pyinstaller_commands(base_dir)
    new_block = f"# BEGIN PYINSTALLER\n{new_commands}\n# END PYINSTALLER"
    if pattern.search(content):
        new_content = pattern.sub(new_block, content)
    else:
        new_content = content.rstrip() + "\n\n" + new_block + "\n"
    with open(build_sh_path, "w") as f:
        f.write(new_content)
    click.echo("Updated build.sh with latest pyinstaller commands.")

def generate_test_script_content(task, base_dir="."):
    return DEFAULT_TEST_TEMPLATE.format(task_name=task.task_name)

def update_test_scripts(base_dir="."):
    tests_dir = os.path.join(base_dir, "tests")
    if not os.path.exists(tests_dir):
        click.echo("tests directory not found, skipping test scripts update.")
        return
    try:
        task_groups, _ = build_task_groups(base_dir)
    except Exception as e:
        click.echo(f"Error updating test scripts: {e}")
        return
    current_test_files = set()
    for group in task_groups:
        for task in group.tasks:
            test_filename = f"test_{task.task_name}.py"
            test_file_path = os.path.join(tests_dir, test_filename)
            content = generate_test_script_content(task, base_dir)
            with open(test_file_path, "w") as f:
                f.write(content)
            current_test_files.add(test_filename)
            click.echo(f"Updated test script for task {task.full_position()}: {test_filename}")
    for f_name in os.listdir(tests_dir):
        if f_name.startswith("test_") and f_name.endswith(".py") and f_name not in current_test_files:
            full_path = os.path.join(tests_dir, f_name)
            click.echo(f"Removing outdated test script: {full_path}")
            os.remove(full_path)

# =============================================================================
# Core Operations: add, delete, and move tasks
# =============================================================================

def add_task(base_dir, pos_str, task_name):
    yaml_path = os.path.join(base_dir, "Mo.yaml")
    if os.path.exists(yaml_path):
        with open(yaml_path, "r") as f:
            mo = yaml.safe_load(f)
    else:
        raise FileNotFoundError("Mo.yaml not found. Please initialize the project first.")
    
    # Check if task name already exists
    tasks_yaml = mo.get("tasks", {})
    for pos, task_value in tasks_yaml.items():
        if isinstance(task_value, dict):
            # Check parallel tasks
            if task_name in task_value.values():
                raise ValueError(f"Task with name '{task_name}' already exists in parallel group at position {pos}")
        else:
            # Check sequential task
            if task_value == task_name:
                raise ValueError(f"Task with name '{task_name}' already exists at position {pos}")
    task_groups, _ = build_task_groups(base_dir)
    current_group_count = len(task_groups)
    pos, letter = parse_position(pos_str)
    tasks_yaml = mo.get("tasks", {})
    if int(pos) > current_group_count + 1:
        raise ValueError(f"Position cannot be more than {current_group_count + 1} (got {pos}).")
    if letter is None:
        if pos not in tasks_yaml:
            tasks_yaml[pos] = task_name
        else:
            shift_task_groups(pos, mo, base_dir)
            tasks_yaml[pos] = task_name
            click.echo(f"Shifted groups from position {pos} onward to insert new sequential task.")
    else:
        if pos not in tasks_yaml:
            tasks_yaml[pos] = {letter: task_name}
        else:
            if isinstance(tasks_yaml[pos], dict):
                if letter in tasks_yaml[pos]:
                    raise ValueError(f"Task {pos}{letter} already exists.")
                tasks_yaml[pos][letter] = task_name
            else:
                existing_task = tasks_yaml[pos]
                old_folder = os.path.join(base_dir, f"{pos}_{existing_task}")
                new_folder = os.path.join(base_dir, f"{pos}b_{existing_task}")
                if os.path.exists(old_folder):
                    if click.confirm(f"Convert sequential task at {pos} to parallel (rename folder '{old_folder}' to '{new_folder}')?", default=False):
                        backup = backup_path(old_folder)
                        click.echo(f"Backed up folder '{old_folder}' to '{backup}'.")
                        rename_path(old_folder, new_folder, base_dir)
                        click.echo(f"Converted sequential task at position {pos} to parallel.")
                    else:
                        raise ValueError("Cannot add parallel task without converting existing serial task.")
                tasks_yaml[pos] = {"b": existing_task, letter: task_name}
    folder_prefix = pos if letter is None else f"{pos}{letter}"
    task_folder = os.path.join(base_dir, f"{folder_prefix}_{task_name}")
    safe_create_directory(task_folder)
    task_file_path = os.path.join(task_folder, f"{task_name}.py")
    safe_write_file(task_file_path, get_task_template(task_name))
    # Do not create a requirements.txt in the task folder.
    wrappers_folder = os.path.join(base_dir, "wrappers")
    if os.path.exists(wrappers_folder):
        wrapper_file_path = os.path.join(wrappers_folder, f"{task_name}_wrapper.py")
        safe_write_file(wrapper_file_path, get_wrapper_template(task_name))
    mo["tasks"] = tasks_yaml
    with open(yaml_path, "w") as f:
        yaml.dump(mo, f)
    click.echo(f"Added task '{task_name}' at position '{pos_str}'. Created folder '{task_folder}'.")
    click.echo("Skipping immediate execution of pyinstaller. The build.sh file has been updated with the pyinstaller commands.")
    update_build_sh(base_dir)
    update_test_scripts(base_dir)
    if os.path.exists(wrappers_folder):
        folder_prefix = pos if letter is None else f"{pos}{letter}"
        task_folder_name = f"{folder_prefix}_{task_name}"
        task_obj = Task(pos, task_name, task_folder_name, letter)
        update_wrapper(base_dir, task_obj)

def delete_task(base_dir, pos_str):
    task_groups, mo = build_task_groups(base_dir)
    tasks_yaml = mo.get("tasks", {})
    pos, letter = parse_position(pos_str)
    if pos not in tasks_yaml:
        raise ValueError(f"No task group found at position {pos}.")
    if letter is None and not isinstance(tasks_yaml[pos], dict):
        folder = os.path.join(base_dir, f"{pos}_{tasks_yaml[pos]}")
        if os.path.exists(folder):
            if click.confirm(f"Delete folder '{folder}'?", default=False):
                backup = backup_path(folder)
                click.echo(f"Backed up folder '{folder}' to '{backup}'.")
                shutil.rmtree(folder)
                click.echo(f"Deleted folder '{folder}'.")
        tasks_yaml.pop(pos)
        shift_task_groups(int(pos)+1, mo, base_dir)
        click.echo(f"Deleted group at position {pos} and shifted later groups.")
    else:
        if not isinstance(tasks_yaml[pos], dict):
            raise ValueError(f"Group at position {pos} is serial; no parallel task to delete.")
        if letter not in tasks_yaml[pos]:
            raise ValueError(f"No task found at position {pos}{letter}.")
        task_name = tasks_yaml[pos].pop(letter)
        folder = os.path.join(base_dir, f"{pos}{letter}_{task_name}")
        if os.path.exists(folder):
            if click.confirm(f"Delete folder '{folder}'?", default=False):
                backup = backup_path(folder)
                click.echo(f"Backed up folder '{folder}' to '{backup}'.")
                shutil.rmtree(folder)
                click.echo(f"Deleted folder '{folder}'.")
        if len(tasks_yaml[pos]) == 1:
            (remaining_letter, remaining_task) = list(tasks_yaml[pos].items())[0]
            old_folder = os.path.join(base_dir, f"{pos}{remaining_letter}_{remaining_task}")
            new_folder = os.path.join(base_dir, f"{pos}_{remaining_task}")
            if os.path.exists(old_folder):
                if click.confirm(f"Flatten group by renaming '{old_folder}' to '{new_folder}'?", default=False):
                    backup = backup_path(old_folder)
                    click.echo(f"Backed up folder '{old_folder}' to '{backup}'.")
                    rename_path(old_folder, new_folder, base_dir)
                    click.echo(f"Flattened group: renamed '{old_folder}' to '{new_folder}'.")
            tasks_yaml[pos] = remaining_task
        click.echo(f"Deleted parallel task at position {pos}{letter}.")
    mo["tasks"] = tasks_yaml
    save_yaml(mo, base_dir)
    update_build_sh(base_dir)
    update_test_scripts(base_dir)

def move_task(base_dir, from_pos_str, to_pos_str):
    task_groups, mo = build_task_groups(base_dir)
    tasks_yaml = mo.get("tasks", {})
    from_num, from_letter = parse_position(from_pos_str)
    if from_num not in tasks_yaml:
        raise ValueError(f"Source position {from_num} not found.")
    if isinstance(tasks_yaml[from_num], dict):
        if not from_letter or from_letter not in tasks_yaml[from_num]:
            raise ValueError(f"Task at {from_pos_str} not found in parallel group.")
        task_name = tasks_yaml[from_num].pop(from_letter)
        source_folder = os.path.join(base_dir, f"{from_num}{from_letter}_{task_name}")
        if len(tasks_yaml[from_num]) == 1:
            (rem_letter, rem_task) = list(tasks_yaml[from_num].items())[0]
            old_folder = os.path.join(base_dir, f"{from_num}{rem_letter}_{rem_task}")
            new_folder = os.path.join(base_dir, f"{from_num}_{rem_task}")
            if os.path.exists(old_folder):
                if click.confirm(f"Flatten group at position {from_num} by renaming '{old_folder}' to '{new_folder}'?", default=False):
                    backup = backup_path(old_folder)
                    click.echo(f"Backed up folder '{old_folder}' to '{backup}'.")
                    rename_path(old_folder, new_folder, base_dir)
                    click.echo(f"Flattened group at position {from_num}.")
            tasks_yaml[from_num] = rem_task
    else:
        if from_letter:
            raise ValueError("No letter expected for a serial task.")
        task_name = tasks_yaml[from_num]
        source_folder = os.path.join(base_dir, f"{from_num}_{task_name}")
        tasks_yaml.pop(from_num)
        shift_task_groups(int(from_num)+1, mo, base_dir)
    to_num, to_letter = parse_position(to_pos_str)
    new_task_groups, _ = build_task_groups(base_dir)
    current_group_count = len(new_task_groups)
    if int(to_num) > current_group_count + 1:
        raise ValueError(f"Destination position cannot be more than {current_group_count + 1}.")
    if to_letter is None:
        if to_num not in tasks_yaml:
            tasks_yaml[to_num] = task_name
        else:
            shift_task_groups(to_num, mo, base_dir)
            tasks_yaml[to_num] = task_name
        dest_folder_prefix = to_num
    else:
        if to_num not in tasks_yaml:
            tasks_yaml[to_num] = {to_letter: task_name}
        else:
            if isinstance(tasks_yaml[to_num], dict):
                if to_letter in tasks_yaml[to_num]:
                    raise ValueError(f"Destination {to_num}{to_letter} already exists.")
                tasks_yaml[to_num][to_letter] = task_name
            else:
                existing_task = tasks_yaml[to_num]
                old_folder = os.path.join(base_dir, f"{to_num}_{existing_task}")
                new_folder_existing = os.path.join(base_dir, f"{to_num}a_{existing_task}")
                if os.path.exists(old_folder):
                    if click.confirm(f"Convert serial group at {to_num} to parallel by renaming '{old_folder}' to '{new_folder_existing}'?", default=False):
                        backup = backup_path(old_folder)
                        click.echo(f"Backed up folder '{old_folder}' to '{backup}'.")
                        rename_path(old_folder, new_folder_existing, base_dir)
                        click.echo(f"Converted serial group at position {to_num} to parallel.")
                    else:
                        raise ValueError("Cannot move into parallel position without converting existing serial task.")
                tasks_yaml[to_num] = {"a": existing_task, to_letter: task_name}
        dest_folder_prefix = f"{to_num}{to_letter}"
    new_folder = os.path.join(base_dir, f"{dest_folder_prefix}_{task_name}")
    if os.path.exists(source_folder):
        shutil.move(source_folder, new_folder)
        click.echo(f"Moved folder from '{source_folder}' to '{new_folder}'.")
    else:
        click.echo(f"Source folder '{source_folder}' does not exist; nothing moved on disk.")
    click.echo(f"Moved task '{task_name}' from {from_pos_str} to {to_pos_str}.")
    mo["tasks"] = tasks_yaml
    save_yaml(mo, base_dir)
    update_build_sh(base_dir)
    update_test_scripts(base_dir)

# =============================================================================
# Updated Wrapper Update Functionality Using SysArgVisitor
# =============================================================================

class SysArgVisitor(ast.NodeVisitor):
    """
    Visits the AST to collect assignments of the form:
        var = sys.argv[<number>]
    Stores a mapping from the index (integer) to the variable name.
    """
    def __init__(self):
        self.params = {}

    def visit_Assign(self, node):
        if isinstance(node.value, ast.Subscript):
            sub = node.value
            if (isinstance(sub.value, ast.Attribute) and
                isinstance(sub.value.value, ast.Name) and
                sub.value.value.id == "sys" and
                sub.value.attr == "argv"):
                index = None
                if isinstance(sub.slice, ast.Constant) and isinstance(sub.slice.value, int):
                    index = sub.slice.value
                elif hasattr(sub.slice, "value") and isinstance(sub.slice.value, int):
                    index = sub.slice.value
                if index is not None:
                    if node.targets and isinstance(node.targets[0], ast.Name):
                        varname = node.targets[0].id
                        self.params[index] = varname
        self.generic_visit(node)

def update_wrapper(base_dir, task):
    """
    Update the wrapper for the given task by parsing the task code to extract
    sys.argv indices and generating explicit assignments for each expected parameter.
    The generated wrapper assigns each CLI argument to a variable (e.g. a = sys.argv[1]).
    """
    task_file = os.path.join(base_dir, task.folder, f"{task.task_name}.py")
    try:
        with open(task_file, "r") as f:
            source = f.read()
        tree = ast.parse(source, filename=task_file)
    except Exception as e:
        click.echo(f"Error parsing task file {task_file}: {e}")
        return

    visitor = SysArgVisitor()
    visitor.visit(tree)
    params = visitor.params

    if not params:
        expected_params = []
    else:
        max_index = max(params.keys())
        expected_params = []
        for i in range(1, max_index + 1):
            expected_params.append(params.get(i, f"param{i}"))

    usage_str = " ".join(expected_params)
    # Generate explicit assignment lines.
    assignment_lines = ""
    for i, var in enumerate(expected_params):
        assignment_lines += f"    {var} = sys.argv[{i+1}]\n"
    # Create an argument list for subprocess.run using the variable names.
    arg_list = ", ".join(expected_params)

    new_wrapper_content = f'''#!/usr/bin/env python3
"""
Wrapper for task: {task.task_name}
This wrapper calls the executable generated by pyinstaller in the dist folder.
It expects the following CLI parameters in order:
    {usage_str}
"""
import sys
import os
import subprocess

def wrapper():
    if len(sys.argv) != {len(expected_params) + 1}:
        print("Usage: {{}} {{}}".format(sys.argv[0], " ".join({expected_params!r})))
        sys.exit(1)
{assignment_lines}
    executable = os.path.join(os.path.dirname(__file__), "..", "dist", "{task.task_name}")
    result = subprocess.run([executable, {arg_list}])
    sys.exit(result.returncode)

if __name__ == '__main__':
    wrapper()
'''
    wrappers_folder = os.path.join(base_dir, "wrappers")
    wrapper_file_path = os.path.join(wrappers_folder, f"{task.task_name}_wrapper.py")
    safe_write_file(wrapper_file_path, new_wrapper_content)
    click.echo(f"Updated wrapper for task {task.full_position()} at {wrapper_file_path}.")

# =============================================================================
# CLI Commands
# =============================================================================

@click.group()
def cli():
    """Model Organizer: manage the project folder structure and tasks."""
    pass

@cli.command()
@click.option('--model', prompt="Model name", help="Name of the model.")
def init(model):
    """Initialize a new model project in the current directory."""
    base_dir = model.replace(" ", "_")
    safe_create_directory(base_dir)
    safe_create_directory(os.path.join(base_dir, "wrappers"))
    safe_create_directory(os.path.join(base_dir, "config"))
    safe_create_directory(os.path.join(base_dir, "tests"))
    safe_create_directory(os.path.join(base_dir, "utils"))
    safe_create_directory(os.path.join(base_dir, "dist"))
    safe_write_file(os.path.join(base_dir, "config", ".env"), "# environment variables go here\n")
    safe_write_file(os.path.join(base_dir, "requirements.txt"), get_requirements_template())
    build_sh_path = os.path.join(base_dir, "build.sh")
    safe_write_file(build_sh_path, get_build_sh_template())
    os.chmod(build_sh_path, 0o755)
    mo = {"model": model, "tasks": {}}
    safe_write_file(os.path.join(base_dir, "Mo.yaml"), yaml.dump(mo))
    click.echo(f"Initialized model '{model}' in {os.path.abspath(base_dir)}.")

@cli.command()
@click.option('--pos', required=True, help="Position for the task (e.g., '1' or '3a').")
@click.option('--name', required=True, help="Name of the task.")
def add(pos, name):
    """Add a new task to the project."""
    try:
        add_task(".", pos, name)
    except Exception as e:
        click.echo(f"Error adding task: {e}")

@cli.command()
@click.option('--pos', required=True, help="Full position of the task to delete (e.g., '3' for serial or '3b' for parallel).")
def delete(pos):
    """Delete a task (or a parallel subtask)."""
    try:
        delete_task(".", pos)
    except Exception as e:
        click.echo(f"Error deleting task: {e}")

@cli.command()
@click.option('--from', 'from_pos', required=True, help="Source position of the task to move (e.g., '3a' or '2').")
@click.option('--to', 'to_pos', required=True, help="Destination position (e.g., '4' or '5a').")
def move(from_pos, to_pos):
    """Move a task from one position to another."""
    try:
        move_task(".", from_pos, to_pos)
    except Exception as e:
        click.echo(f"Error moving task: {e}")

@cli.command()
def validate():
    """Validate that Mo.yaml and task folders are consistent."""
    try:
        task_groups, _ = build_task_groups(".")
        click.echo("Validation successful. Current tasks (doubly linked list):")
        for group in task_groups:
            prev_str = f"{group.prev.pos}" if group.prev else "None"
            next_str = f"{group.next.pos}" if group.next else "None"
            click.echo(f"Group {group.pos} (prev: {prev_str}, next: {next_str}):")
            for t in group.tasks:
                click.echo(f"  - {t.full_position()}: {t.task_name}")
    except Exception as e:
        click.echo(f"Validation error: {e}")

@cli.group()
def wrapper():
    """Manage task wrappers."""
    pass

@wrapper.command('update')
@click.option('--pos', help="Optional: task position (e.g., '3' or '3a') to update wrapper for. If not provided, update all wrappers.")
def wrapper_update(pos):
    base_dir = "."
    try:
        task_groups, _ = build_task_groups(base_dir)
    except Exception as e:
        click.echo(f"Error: {e}")
        return
    tasks_to_update = []
    if pos:
        for group in task_groups:
            for task in group.tasks:
                if task.full_position() == pos:
                    tasks_to_update.append(task)
        if not tasks_to_update:
            click.echo(f"No task found at position {pos}.")
            return
    else:
        if click.confirm("No task position provided. Update wrappers for all tasks?", default=False):
            for group in task_groups:
                tasks_to_update.extend(group.tasks)
        else:
            click.echo("Aborted updating wrappers.")
            return
    for task in tasks_to_update:
        update_wrapper(base_dir, task)

if __name__ == '__main__':
    cli()
